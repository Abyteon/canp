# 任务要求

目前有8000个15m的文件，内部数据格式如下：

1. 35 个字节的头部，后四个字节的大端序为后续数据长度，后续数据为压缩数据。压缩数据大概10kb。这样的结构在文件中重复。头部中的（前18个字节）序列号的内容需要再后续处理中一直保存。

2. 解压后的数据，20个字节的头部，后四个字节的大端序为后续数据长度, 后续数据未压缩, 为许多帧序列拼接成的数据。这样的结构重复出现。

3. 16个字节的长度， 12到15四个字节的大端序为后续数据长度，后续数据为一个帧序列，由多个单帧组成。这样的结构重复出现。前四个字节（can版本也要保存）

4. 单帧，需要按照 dbc 文件进行解析。

然后输出到文件，考虑采用列式存储，最后的结果除了单帧的解析结果，还要保留部分上层的头部信息。

目前已经实现了一个零拷贝，支持文件mmap，和数据内存分配的内存池。

处理流程大概是这样：

1. 从目录并发映射文件到mmap，内存池分配mmap，返回指针和长度确保能找到数据。每个文件仅处理一次，
2. 然后批量收集序列号和对应压缩块的指针，并发解压这些压缩块，内存池为解压后的每个数据分配内存，返回指针和长度，确保能找到数据。
3. 后续的解析就不在需要分配内存，之后是并发在这些解压数据中分层批量并发解析数据。通过指针和长度定位数据，实现零拷贝。
   <!-- 4. 使用dbc解析后的数据写入文件，按列式存储。 -->
      <!-- 还有一个要解决的问题是，是否要采取批处理模式， -->

<!-- 评估一下目前这个方案的可行性和性能，并讨论一下批处理这里是优还是劣。 -->

要求借鉴社区优秀案例，采用优秀的三方库。代码逻辑清晰，易于维护。
dbc解析库采用can-dbc。

那么现在检查一下剩余模块,结合我们已经实现的内存池和线程池。

给一个剩余模块的方案
