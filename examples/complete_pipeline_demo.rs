//! # å®Œæ•´æ•°æ®å¤„ç†ç®¡é“ç¤ºä¾‹
//! 
//! å±•ç¤ºæ•´ä¸ªç³»ç»Ÿçš„ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹ï¼š
//! 1. ç”Ÿæˆæµ‹è¯•æ•°æ®
//! 2. åˆ›å»ºDBCæ–‡ä»¶
//! 3. è¿è¡Œå®Œæ•´å¤„ç†ç®¡é“
//! 4. è¾“å‡ºç»“æœåˆ†æ

use canp::processing_pipeline::{DataProcessingPipeline, PipelineConfig};
use canp::test_data_generator::{TestDataGenerator, TestDataConfig};
use canp::columnar_storage::{ColumnarStorageConfig, CompressionType, PartitionStrategy};
use anyhow::Result;
use std::path::PathBuf;
use tracing_subscriber;

#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    tracing_subscriber::fmt()
        .with_env_filter("info,canp=debug")
        .init();
    
    println!("ğŸš€ æ¬¢è¿ä½¿ç”¨CANæ•°æ®å¤„ç†ç®¡é“å®Œæ•´ç¤ºä¾‹ï¼");
    println!("{}", "=".repeat(60));
    
    // ç¬¬1æ­¥ï¼šå‡†å¤‡å·¥ä½œç¯å¢ƒ
    println!("ğŸ“‹ ç¬¬1æ­¥ï¼šå‡†å¤‡å·¥ä½œç¯å¢ƒ");
    let workspace = prepare_workspace().await?;
    
    // ç¬¬2æ­¥ï¼šç”Ÿæˆæµ‹è¯•æ•°æ®
    println!("\nğŸ“‹ ç¬¬2æ­¥ï¼šç”Ÿæˆæµ‹è¯•æ•°æ®");
    let test_files = generate_test_data(&workspace).await?;
    
    // ç¬¬3æ­¥ï¼šåˆ›å»ºDBCæ–‡ä»¶
    println!("\nğŸ“‹ ç¬¬3æ­¥ï¼šåˆ›å»ºDBCæ–‡ä»¶");
    let dbc_files = create_dbc_files(&workspace).await?;
    
    // ç¬¬4æ­¥ï¼šé…ç½®å’Œåˆ›å»ºå¤„ç†ç®¡é“
    println!("\nğŸ“‹ ç¬¬4æ­¥ï¼šé…ç½®å¤„ç†ç®¡é“");
    let pipeline = create_processing_pipeline(&workspace).await?;
    
    // ç¬¬5æ­¥ï¼šåŠ è½½DBCæ–‡ä»¶
    println!("\nğŸ“‹ ç¬¬5æ­¥ï¼šåŠ è½½DBCæ–‡ä»¶");
    pipeline.load_dbc_files(dbc_files).await?;
    
    // ç¬¬6æ­¥ï¼šè¿è¡Œå®Œæ•´å¤„ç†ç®¡é“
    println!("\nğŸ“‹ ç¬¬6æ­¥ï¼šè¿è¡Œæ•°æ®å¤„ç†ç®¡é“");
    let results = pipeline.process_files(test_files).await?;
    
    // ç¬¬7æ­¥ï¼šåˆ†æå¤„ç†ç»“æœ
    println!("\nğŸ“‹ ç¬¬7æ­¥ï¼šåˆ†æå¤„ç†ç»“æœ");
    analyze_results(&pipeline, &results, &workspace).await?;
    
    println!("\nğŸ‰ å®Œæ•´æ•°æ®å¤„ç†ç®¡é“ç¤ºä¾‹æ‰§è¡Œå®Œæˆï¼");
    println!("ğŸ’¡ æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ç›®å½•æŸ¥çœ‹è¾“å‡ºç»“æœ:");
    println!("   ğŸ“ åˆ—å¼å­˜å‚¨æ–‡ä»¶: {}", workspace.join("output").display());
    println!("   ğŸ“Š å¤„ç†æ—¥å¿—: æ§åˆ¶å°è¾“å‡º");
    
    Ok(())
}

/// å·¥ä½œç¯å¢ƒé…ç½®
struct Workspace {
    base_dir: PathBuf,
    test_data_dir: PathBuf,
    dbc_dir: PathBuf,
    output_dir: PathBuf,
}

impl Workspace {
    fn new(base_dir: PathBuf) -> Self {
        Self {
            test_data_dir: base_dir.join("test_data"),
            dbc_dir: base_dir.join("dbc_files"),
            output_dir: base_dir.join("output"),
            base_dir,
        }
    }
    
    fn join(&self, path: &str) -> PathBuf {
        self.base_dir.join(path)
    }
}

/// å‡†å¤‡å·¥ä½œç¯å¢ƒ
async fn prepare_workspace() -> Result<Workspace> {
    let base_dir = std::env::current_dir()?.join("pipeline_demo_workspace");
    let workspace = Workspace::new(base_dir);
    
    // åˆ›å»ºå¿…è¦çš„ç›®å½•
    for dir in [&workspace.test_data_dir, &workspace.dbc_dir, &workspace.output_dir] {
        tokio::fs::create_dir_all(dir).await?;
        println!("  âœ… åˆ›å»ºç›®å½•: {}", dir.display());
    }
    
    println!("ğŸ¯ å·¥ä½œç¯å¢ƒå‡†å¤‡å®Œæˆ: {}", workspace.base_dir.display());
    Ok(workspace)
}

/// ç”Ÿæˆæµ‹è¯•æ•°æ®
async fn generate_test_data(workspace: &Workspace) -> Result<Vec<PathBuf>> {
    println!("  ğŸ”§ é…ç½®æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨...");
    
    let config = TestDataConfig {
        file_count: 100,  // ç”Ÿæˆ100ä¸ªæµ‹è¯•æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿå®é™…çš„8000ä¸ªï¼‰
        target_file_size: 15 * 1024 * 1024,  // 15MB
        frames_per_file: 2000,  // æ¯ä¸ªæ–‡ä»¶2000å¸§
        output_dir: workspace.test_data_dir.clone(),
    };
    
    println!("  ğŸ“Š æµ‹è¯•æ•°æ®é…ç½®:");
    println!("    ğŸ“„ æ–‡ä»¶æ•°é‡: {}", config.file_count);
    println!("    ğŸ“ å•æ–‡ä»¶å¤§å°: {} MB", config.target_file_size / 1024 / 1024);
    println!("    ğŸ² æ¯æ–‡ä»¶å¸§æ•°: {}", config.frames_per_file);
    
    let generator = TestDataGenerator::new(config);
    let file_paths = generator.generate_all().await?;
    
    println!("  âœ… æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆ: {} ä¸ªæ–‡ä»¶", file_paths.len());
    
    // éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
    let mut total_size = 0u64;
    for path in &file_paths {
        if let Ok(metadata) = tokio::fs::metadata(path).await {
            total_size += metadata.len();
        }
    }
    
    println!("  ğŸ“Š æ€»æ•°æ®é‡: {:.2} GB", total_size as f64 / 1024.0 / 1024.0 / 1024.0);
    
    Ok(file_paths)
}

/// åˆ›å»ºDBCæ–‡ä»¶
async fn create_dbc_files(workspace: &Workspace) -> Result<Vec<PathBuf>> {
    println!("  ğŸ”§ åˆ›å»ºç¤ºä¾‹DBCæ–‡ä»¶...");
    
    // åˆ›å»ºå¤šä¸ªDBCæ–‡ä»¶æ¥æ¼”ç¤ºå¤šDBCåœºæ™¯
    let dbc_configs = vec![
        ("engine.dbc", create_engine_dbc_content()),
        ("chassis.dbc", create_chassis_dbc_content()),
        ("body.dbc", create_body_dbc_content()),
    ];
    
    let mut dbc_files = Vec::new();
    
    for (filename, content) in dbc_configs {
        let dbc_path = workspace.dbc_dir.join(filename);
        tokio::fs::write(&dbc_path, content).await?;
        dbc_files.push(dbc_path.clone());
        println!("  âœ… åˆ›å»ºDBCæ–‡ä»¶: {}", dbc_path.display());
    }
    
    println!("  ğŸ“Š DBCæ–‡ä»¶åˆ›å»ºå®Œæˆ: {} ä¸ªæ–‡ä»¶", dbc_files.len());
    Ok(dbc_files)
}

/// åˆ›å»ºå¼•æ“ç›¸å…³çš„DBCå†…å®¹
fn create_engine_dbc_content() -> String {
    r#"
VERSION ""

NS_ : 
	NS_DESC_
	CM_
	BA_DEF_
	BA_
	VAL_
	CAT_DEF_
	CAT_
	FILTER
	BA_DEF_DEF_
	EV_DATA_
	ENVVAR_DATA_
	SGTYPE_
	SGTYPE_VAL_
	BA_DEF_SGTYPE_
	SIG_VALTYPE_
	SIGTYPE_VALTYPE_
	BO_TX_BU_
	BA_DEF_REL_
	BA_REL_
	BA_DEF_DEF_REL_
	BU_SG_REL_
	BU_EV_REL_
	BU_BO_REL_
	SG_MUL_VAL_

BS_:

BU_: ECU_Engine ECU_Transmission

BO_ 256 Engine_RPM: 8 ECU_Engine
 SG_ Engine_Speed : 0|16@1+ (0.25,0) [0|16383.75] "rpm" ECU_Transmission
 SG_ Engine_Load : 16|8@1+ (0.4,0) [0|102] "%" ECU_Transmission
 SG_ Coolant_Temp : 24|8@1+ (1,-40) [-40|215] "Â°C" ECU_Transmission
 SG_ Fuel_Level : 32|8@1+ (0.4,0) [0|102] "%" ECU_Transmission

BO_ 512 Engine_Status: 8 ECU_Engine
 SG_ Engine_Running : 0|1@1+ (1,0) [0|1] "" ECU_Transmission
 SG_ Check_Engine : 1|1@1+ (1,0) [0|1] "" ECU_Transmission
 SG_ Oil_Pressure : 8|16@1+ (0.1,0) [0|6553.5] "kPa" ECU_Transmission

CM_ SG_ 256 Engine_Speed "Engine rotational speed";
CM_ SG_ 256 Engine_Load "Engine load percentage";
CM_ SG_ 512 Engine_Running "Engine running status";

VAL_ 512 Engine_Running 0 "Stopped" 1 "Running";
VAL_ 512 Check_Engine 0 "OK" 1 "Warning";
"#.to_string()
}

/// åˆ›å»ºåº•ç›˜ç›¸å…³çš„DBCå†…å®¹
fn create_chassis_dbc_content() -> String {
    r#"
VERSION ""

NS_ : 
	NS_DESC_
	CM_
	BA_DEF_
	BA_
	VAL_
	CAT_DEF_
	CAT_
	FILTER
	BA_DEF_DEF_
	EV_DATA_
	ENVVAR_DATA_
	SGTYPE_
	SGTYPE_VAL_
	BA_DEF_SGTYPE_
	SIG_VALTYPE_
	SIGTYPE_VALTYPE_
	BO_TX_BU_
	BA_DEF_REL_
	BA_REL_
	BA_DEF_DEF_REL_
	BU_SG_REL_
	BU_EV_REL_
	BU_BO_REL_
	SG_MUL_VAL_

BS_:

BU_: ECU_ABS ECU_ESP

BO_ 768 Vehicle_Speed: 8 ECU_ABS
 SG_ Vehicle_Speed : 0|16@1+ (0.0625,0) [0|4095.9375] "km/h" ECU_ESP
 SG_ Wheel_Speed_FL : 16|16@1+ (0.0625,0) [0|4095.9375] "km/h" ECU_ESP
 SG_ Wheel_Speed_FR : 32|16@1+ (0.0625,0) [0|4095.9375] "km/h" ECU_ESP
 SG_ Wheel_Speed_RL : 48|16@1+ (0.0625,0) [0|4095.9375] "km/h" ECU_ESP

BO_ 1024 Brake_Status: 8 ECU_ABS
 SG_ Brake_Pedal_Pos : 0|8@1+ (0.4,0) [0|102] "%" ECU_ESP
 SG_ ABS_Active : 8|1@1+ (1,0) [0|1] "" ECU_ESP
 SG_ ESP_Active : 9|1@1+ (1,0) [0|1] "" ECU_ESP

CM_ SG_ 768 Vehicle_Speed "Vehicle speed from ABS sensor";
CM_ SG_ 1024 ABS_Active "ABS system activation status";

VAL_ 1024 ABS_Active 0 "Inactive" 1 "Active";
VAL_ 1024 ESP_Active 0 "Inactive" 1 "Active";
"#.to_string()
}

/// åˆ›å»ºè½¦èº«ç›¸å…³çš„DBCå†…å®¹
fn create_body_dbc_content() -> String {
    r#"
VERSION ""

NS_ : 
	NS_DESC_
	CM_
	BA_DEF_
	BA_
	VAL_
	CAT_DEF_
	CAT_
	FILTER
	BA_DEF_DEF_
	EV_DATA_
	ENVVAR_DATA_
	SGTYPE_
	SGTYPE_VAL_
	BA_DEF_SGTYPE_
	SIG_VALTYPE_
	SIGTYPE_VALTYPE_
	BO_TX_BU_
	BA_DEF_REL_
	BA_REL_
	BA_DEF_DEF_REL_
	BU_SG_REL_
	BU_EV_REL_
	BU_BO_REL_
	SG_MUL_VAL_

BS_:

BU_: ECU_BCM ECU_Climate

BO_ 1280 Door_Status: 8 ECU_BCM
 SG_ Door_FL_Open : 0|1@1+ (1,0) [0|1] "" ECU_Climate
 SG_ Door_FR_Open : 1|1@1+ (1,0) [0|1] "" ECU_Climate
 SG_ Door_RL_Open : 2|1@1+ (1,0) [0|1] "" ECU_Climate
 SG_ Door_RR_Open : 3|1@1+ (1,0) [0|1] "" ECU_Climate
 SG_ Trunk_Open : 4|1@1+ (1,0) [0|1] "" ECU_Climate

BO_ 1536 Climate_Control: 8 ECU_Climate
 SG_ AC_Status : 0|1@1+ (1,0) [0|1] "" ECU_BCM
 SG_ Fan_Speed : 8|4@1+ (1,0) [0|15] "" ECU_BCM
 SG_ Target_Temp : 16|8@1+ (0.5,0) [0|127.5] "Â°C" ECU_BCM
 SG_ Ambient_Temp : 24|8@1+ (1,-40) [-40|215] "Â°C" ECU_BCM

CM_ SG_ 1280 Door_FL_Open "Front left door status";
CM_ SG_ 1536 AC_Status "Air conditioning status";

VAL_ 1280 Door_FL_Open 0 "Closed" 1 "Open";
VAL_ 1536 AC_Status 0 "Off" 1 "On";
"#.to_string()
}

/// åˆ›å»ºå¤„ç†ç®¡é“
async fn create_processing_pipeline(workspace: &Workspace) -> Result<DataProcessingPipeline> {
    println!("  ğŸ”§ é…ç½®å¤„ç†ç®¡é“å‚æ•°...");
    
    let config = PipelineConfig {
        storage_config: ColumnarStorageConfig {
            output_dir: workspace.output_dir.clone(),
            compression: CompressionType::Zstd, // ä½¿ç”¨Zstdå‹ç¼©è·å¾—æ›´å¥½çš„å‹ç¼©æ¯”
            partition_strategy: PartitionStrategy::Daily, // æŒ‰å¤©åˆ†åŒº
            batch_size: 1000, // 1000è¡Œä¸€æ‰¹
            max_file_size: 50 * 1024 * 1024, // 50MBä¸€ä¸ªæ–‡ä»¶
            keep_raw_data: false, // ä¸ä¿ç•™åŸå§‹æ•°æ®ä»¥èŠ‚çœç©ºé—´
            ..ColumnarStorageConfig::default()
        },
        batch_size: 20, // 20ä¸ªæ–‡ä»¶ä¸€æ‰¹å¤„ç†
        max_concurrent_files: num_cpus::get().min(8), // é™åˆ¶å¹¶å‘æ•°
        enable_error_recovery: true,
        max_retries: 2,
        enable_progress_reporting: true,
        progress_report_interval: 10, // æ¯10ç§’æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
        ..PipelineConfig::default()
    };
    
    println!("  ğŸ“Š ç®¡é“é…ç½®:");
    println!("    ğŸ”„ æ‰¹å¤„ç†å¤§å°: {} æ–‡ä»¶/æ‰¹", config.batch_size);
    println!("    ğŸš€ æœ€å¤§å¹¶å‘æ•°: {} æ–‡ä»¶", config.max_concurrent_files);
    println!("    ğŸ“¦ å­˜å‚¨å‹ç¼©: {:?}", config.storage_config.compression);
    println!("    ğŸ“ åˆ†åŒºç­–ç•¥: {:?}", config.storage_config.partition_strategy);
    println!("    ğŸ”„ é”™è¯¯é‡è¯•: {} æ¬¡", config.max_retries);
    
    let pipeline = DataProcessingPipeline::new(config).await?;
    println!("  âœ… å¤„ç†ç®¡é“åˆ›å»ºå®Œæˆ");
    
    Ok(pipeline)
}

/// åˆ†æå¤„ç†ç»“æœ
async fn analyze_results(
    pipeline: &DataProcessingPipeline, 
    batch_results: &[canp::processing_pipeline::BatchProcessingResult],
    workspace: &Workspace
) -> Result<()> {
    
    println!("  ğŸ“Š åˆ†ææ‰¹å¤„ç†ç»“æœ...");
    
    // æ±‡æ€»æ‰¹æ¬¡ç»Ÿè®¡
    let mut total_files = 0;
    let mut successful_files = 0;
    let mut failed_files = 0;
    let mut total_processing_time = 0u64;
    let mut total_throughput = 0.0;
    
    for (batch_index, batch_result) in batch_results.iter().enumerate() {
        println!("    ğŸ“¦ æ‰¹æ¬¡ {}: æˆåŠŸ {}, å¤±è´¥ {}, ååé‡ {:.2} MB/s",
            batch_index + 1,
            batch_result.successful_files,
            batch_result.failed_files,
            batch_result.batch_throughput_mb_s
        );
        
        total_files += batch_result.successful_files + batch_result.failed_files;
        successful_files += batch_result.successful_files;
        failed_files += batch_result.failed_files;
        total_processing_time += batch_result.batch_time_ms;
        total_throughput += batch_result.batch_throughput_mb_s;
    }
    
    let avg_throughput = if batch_results.len() > 0 {
        total_throughput / batch_results.len() as f64
    } else {
        0.0
    };
    
    println!("\n  ğŸ¯ æ‰¹å¤„ç†æ±‡æ€»:");
    println!("    ğŸ“„ æ€»æ–‡ä»¶æ•°: {}", total_files);
    println!("    âœ… æˆåŠŸå¤„ç†: {} ({:.1}%)", 
        successful_files, 
        if total_files > 0 { successful_files as f64 / total_files as f64 * 100.0 } else { 0.0 }
    );
    println!("    âŒ å¤„ç†å¤±è´¥: {} ({:.1}%)", 
        failed_files,
        if total_files > 0 { failed_files as f64 / total_files as f64 * 100.0 } else { 0.0 }
    );
    println!("    â±ï¸ æ€»å¤„ç†æ—¶é—´: {:.2} åˆ†é’Ÿ", total_processing_time as f64 / 60000.0);
    println!("    ğŸš€ å¹³å‡ååé‡: {:.2} MB/s", avg_throughput);
    
    // è·å–è¯¦ç»†ç®¡é“ç»Ÿè®¡
    println!("\n  ğŸ“ˆ è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯...");
    let stats = pipeline.get_stats().await;
    stats.print_detailed_summary();
    
    // æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
    println!("\n  ğŸ“ æ£€æŸ¥è¾“å‡ºæ–‡ä»¶...");
    analyze_output_files(&workspace.output_dir).await?;
    
    // æ€§èƒ½å»ºè®®
    println!("\n  ğŸ’¡ æ€§èƒ½åˆ†æå’Œå»ºè®®:");
    provide_performance_recommendations(&stats, avg_throughput);
    
    Ok(())
}

/// åˆ†æè¾“å‡ºæ–‡ä»¶
async fn analyze_output_files(output_dir: &PathBuf) -> Result<()> {
    let mut output_files = Vec::new();
    let mut total_output_size = 0u64;
    
    // é€’å½’éå†è¾“å‡ºç›®å½•
    let mut stack = vec![output_dir.clone()];
    
    while let Some(current_dir) = stack.pop() {
        if let Ok(mut entries) = tokio::fs::read_dir(&current_dir).await {
            while let Ok(Some(entry)) = entries.next_entry().await {
                let path = entry.path();
                if path.is_dir() {
                    stack.push(path);
                } else if path.extension().map_or(false, |ext| ext == "parquet") {
                    if let Ok(metadata) = entry.metadata().await {
                        output_files.push((path.clone(), metadata.len()));
                        total_output_size += metadata.len();
                    }
                }
            }
        }
    }
    
    println!("    ğŸ“„ è¾“å‡ºæ–‡ä»¶æ•°: {}", output_files.len());
    println!("    ğŸ’¾ æ€»è¾“å‡ºå¤§å°: {:.2} MB", total_output_size as f64 / 1024.0 / 1024.0);
    
    if !output_files.is_empty() {
        let avg_file_size = total_output_size / output_files.len() as u64;
        println!("    ğŸ“Š å¹³å‡æ–‡ä»¶å¤§å°: {:.2} MB", avg_file_size as f64 / 1024.0 / 1024.0);
        
        // æ˜¾ç¤ºå‰å‡ ä¸ªè¾“å‡ºæ–‡ä»¶
        println!("    ğŸ“ è¾“å‡ºæ–‡ä»¶ç¤ºä¾‹:");
        for (i, (path, size)) in output_files.iter().take(5).enumerate() {
            println!("      {} - {} ({:.2} MB)", 
                i + 1, 
                path.display(), 
                *size as f64 / 1024.0 / 1024.0
            );
        }
        
        if output_files.len() > 5 {
            println!("      ... è¿˜æœ‰ {} ä¸ªæ–‡ä»¶", output_files.len() - 5);
        }
    }
    
    // æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶
    let metadata_path = output_dir.join("_metadata.json");
    if metadata_path.exists() {
        println!("    âœ… å…ƒæ•°æ®æ–‡ä»¶å·²ç”Ÿæˆ: {}", metadata_path.display());
    }
    
    Ok(())
}

/// æä¾›æ€§èƒ½å»ºè®®
fn provide_performance_recommendations(stats: &canp::processing_pipeline::PipelineStats, avg_throughput: f64) {
    println!("    ğŸ¯ åŸºäºå¤„ç†ç»“æœçš„ä¼˜åŒ–å»ºè®®:");
    
    // æˆåŠŸç‡åˆ†æ
    let success_rate = if stats.total_files > 0 {
        stats.successful_files as f64 / stats.total_files as f64
    } else {
        0.0
    };
    
    if success_rate < 0.95 {
        println!("      âš ï¸ æ–‡ä»¶å¤„ç†æˆåŠŸç‡è¾ƒä½ ({:.1}%)ï¼Œå»ºè®®æ£€æŸ¥:", success_rate * 100.0);
        println!("         - DBCæ–‡ä»¶å®Œæ•´æ€§");
        println!("         - æµ‹è¯•æ•°æ®æ ¼å¼");
        println!("         - é”™è¯¯é‡è¯•æœºåˆ¶");
    } else {
        println!("      âœ… æ–‡ä»¶å¤„ç†æˆåŠŸç‡è‰¯å¥½ ({:.1}%)", success_rate * 100.0);
    }
    
    // ååé‡åˆ†æ
    if avg_throughput < 50.0 {
        println!("      âš ï¸ å¹³å‡ååé‡è¾ƒä½ ({:.2} MB/s)ï¼Œå»ºè®®ä¼˜åŒ–:", avg_throughput);
        println!("         - å¢åŠ å¹¶å‘å¤„ç†æ•°");
        println!("         - è°ƒæ•´æ‰¹å¤„ç†å¤§å°");
        println!("         - ä½¿ç”¨æ›´å¿«çš„å­˜å‚¨è®¾å¤‡");
        println!("         - ä¼˜åŒ–DBCè§£æç¼“å­˜");
    } else if avg_throughput < 100.0 {
        println!("      ğŸ”¶ å¹³å‡ååé‡ä¸­ç­‰ ({:.2} MB/s)ï¼Œå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–:", avg_throughput);
        println!("         - è°ƒä¼˜å†…å­˜æ± é…ç½®");
        println!("         - ä¼˜åŒ–åˆ—å¼å­˜å‚¨å‹ç¼©è®¾ç½®");
    } else {
        println!("      ğŸš€ å¹³å‡ååé‡ä¼˜ç§€ ({:.2} MB/s)", avg_throughput);
    }
    
    // å†…å­˜ä½¿ç”¨åˆ†æ
    let memory_gb = stats.peak_memory_usage as f64 / 1024.0 / 1024.0 / 1024.0;
    if memory_gb > 8.0 {
        println!("      âš ï¸ å³°å€¼å†…å­˜ä½¿ç”¨è¾ƒé«˜ ({:.2} GB)ï¼Œå»ºè®®:", memory_gb);
        println!("         - å‡å°‘æ‰¹å¤„ç†å¤§å°");
        println!("         - å¯ç”¨æ›´ç§¯æçš„åƒåœ¾å›æ”¶");
        println!("         - ä¼˜åŒ–å†…å­˜æ± é…ç½®");
    } else {
        println!("      âœ… å†…å­˜ä½¿ç”¨åˆç† ({:.2} GB)", memory_gb);
    }
    
    // DBCè§£æä¼˜åŒ–å»ºè®®
    if stats.dbc_parsing_stats.cache_hit_rate < 0.8 {
        println!("      ğŸ”¶ DBCç¼“å­˜å‘½ä¸­ç‡è¾ƒä½ ({:.1}%)ï¼Œå»ºè®®:", 
            stats.dbc_parsing_stats.cache_hit_rate * 100.0);
        println!("         - å¢åŠ DBCç¼“å­˜å¤§å°");
        println!("         - æ£€æŸ¥CAN IDåˆ†å¸ƒ");
    }
    
    // é’ˆå¯¹8000æ–‡ä»¶çš„å®é™…åœºæ™¯å»ºè®®
    println!("      ğŸ’¡ é’ˆå¯¹å®é™…8000æ–‡ä»¶å¤„ç†çš„å»ºè®®:");
    println!("         - æ‰¹å¤„ç†å¤§å°å»ºè®®: 50-100 æ–‡ä»¶/æ‰¹");
    println!("         - æ¨èå¹¶å‘æ•°: {}-{} (å½“å‰CPUæ ¸å¿ƒæ•°: {})", 
        num_cpus::get(), num_cpus::get() * 2, num_cpus::get());
    println!("         - é¢„è®¡å¤„ç†æ—¶é—´: {:.1}-{:.1} å°æ—¶", 
        8000.0 / stats.successful_files as f64 * stats.total_processing_time_ms as f64 / 3600000.0 * 0.8,
        8000.0 / stats.successful_files as f64 * stats.total_processing_time_ms as f64 / 3600000.0 * 1.2
    );
    println!("         - å»ºè®®å­˜å‚¨ç©ºé—´: {:.1} GB", 
        8000.0 / stats.total_files as f64 * stats.storage_stats.compressed_size as f64 / 1024.0 / 1024.0 / 1024.0
    );
}