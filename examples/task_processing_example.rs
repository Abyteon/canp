//! # æ•°æ®å¤„ç†ä»»åŠ¡ç¤ºä¾‹
//! 
//! å±•ç¤ºå¦‚ä½•ä½¿ç”¨ZeroCopyMemoryPoolå¤„ç†å¤§è§„æ¨¡æ–‡ä»¶çš„å®Œæ•´æµç¨‹

use canp::zero_copy_memory_pool::{ZeroCopyMemoryPool, MemoryPoolConfig};
use anyhow::Result;
use std::path::PathBuf;

use flate2::read::GzDecoder;
use std::io::Read;
use tracing::{info, error, warn};

/// æ¨¡æ‹Ÿçš„æ•°æ®å¤„ç†ä»»åŠ¡
struct DataProcessingTask {
    /// å†…å­˜æ± 
    pool: ZeroCopyMemoryPool,
    /// æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    file_paths: Vec<PathBuf>,
}

impl DataProcessingTask {
    /// åˆ›å»ºæ–°çš„æ•°æ®å¤„ç†ä»»åŠ¡
    pub fn new(file_paths: Vec<PathBuf>) -> Self {
        let config = MemoryPoolConfig {
            // é’ˆå¯¹æ‚¨çš„æ•°æ®ç‰¹å¾ä¼˜åŒ–
            decompress_buffer_sizes: vec![
                16 * 1024,   // 16KB - å¯¹åº”~10KBå‹ç¼©æ•°æ®
                64 * 1024,   // 64KB - ä¸­ç­‰è§£å‹ç»“æœ
                256 * 1024,  // 256KB - å¤§å‹è§£å‹ç»“æœ
                1024 * 1024, // 1MB - è¶…å¤§è§£å‹ç»“æœ
            ],
            mmap_cache_size: 500, // ç¼“å­˜500ä¸ª15MBæ–‡ä»¶
            max_memory_usage: 4 * 1024 * 1024 * 1024, // 4GBé™åˆ¶
        };

        Self {
            pool: ZeroCopyMemoryPool::new(config),
            file_paths,
        }
    }

    /// å¤„ç†å•ä¸ªæ–‡ä»¶çš„å®Œæ•´æµç¨‹
    pub async fn process_single_file(&self, file_path: &PathBuf) -> Result<ProcessingResult> {
        info!("ğŸ“ å¼€å§‹å¤„ç†æ–‡ä»¶: {:?}", file_path);

        // 1. é›¶æ‹·è´æ–‡ä»¶æ˜ å°„ (mmap)
        let file_mapping = self.pool.create_file_mapping(file_path)
            .map_err(|e| anyhow::anyhow!("æ–‡ä»¶æ˜ å°„å¤±è´¥: {}", e))?;

        info!("ğŸ—ºï¸ æ–‡ä»¶æ˜ å°„å®Œæˆ: {} bytes", file_mapping.len());

        // 2. è§£ææ–‡ä»¶å¤´éƒ¨ï¼ˆ35å­—èŠ‚ï¼‰
        if file_mapping.len() < 35 {
            return Err(anyhow::anyhow!("æ–‡ä»¶å¤ªå°ï¼Œæ— æ³•åŒ…å«å®Œæ•´å¤´éƒ¨"));
        }

        let header = file_mapping.slice(0, 35);
        // æ ¹æ®ä»»åŠ¡è¦æ±‚ï¼š35å­—èŠ‚å¤´éƒ¨çš„"åå››ä¸ªå­—èŠ‚"ï¼ˆä½ç½®31-34ï¼‰ä¸ºå‹ç¼©æ•°æ®é•¿åº¦
        let compressed_data_length = u32::from_be_bytes([
            header[31], header[32], header[33], header[34]
        ]) as usize;

        info!("ğŸ“‹ å¤´éƒ¨è§£æå®Œæˆï¼Œå‹ç¼©æ•°æ®é•¿åº¦: {} bytes", compressed_data_length);

        // 3. æå–å‹ç¼©æ•°æ®ï¼ˆé›¶æ‹·è´ï¼‰
        if file_mapping.len() < 35 + compressed_data_length {
            return Err(anyhow::anyhow!("æ–‡ä»¶é•¿åº¦ä¸è¶³ï¼Œæ— æ³•åŒ…å«å®Œæ•´å‹ç¼©æ•°æ®"));
        }

        let compressed_data = file_mapping.slice(35, compressed_data_length);
        info!("ğŸ“¦ å‹ç¼©æ•°æ®æå–å®Œæˆ: {} bytes", compressed_data.len());

        // 4. è§£å‹æ•°æ®ï¼ˆéœ€è¦å†…å­˜åˆ†é…ï¼‰
        let decompressed_data = self.decompress_data(compressed_data).await?;
        info!("ğŸ”“ æ•°æ®è§£å‹å®Œæˆ: {} bytes", decompressed_data.len());

        // 5. è§£æè§£å‹åçš„æ•°æ®å¤´éƒ¨ï¼ˆ20å­—èŠ‚ï¼‰
        let decompressed_slice = decompressed_data.as_slice();
        if decompressed_slice.len() < 20 {
            return Err(anyhow::anyhow!("è§£å‹æ•°æ®å¤ªå°ï¼Œæ— æ³•åŒ…å«å®Œæ•´å¤´éƒ¨"));
        }

        let decompressed_header = &decompressed_slice[0..20];
        let frame_data_length = u32::from_be_bytes([
            decompressed_header[16], decompressed_header[17], 
            decompressed_header[18], decompressed_header[19]
        ]) as usize;

        info!("ğŸ“Š è§£å‹å¤´éƒ¨è§£æå®Œæˆï¼Œå¸§æ•°æ®é•¿åº¦: {} bytes", frame_data_length);

        // 6. å¤„ç†å¸§åºåˆ—æ•°æ®ï¼ˆé›¶æ‹·è´ï¼‰
        let frame_results = self.process_frame_sequences(
            &decompressed_data, 
            20, 
            frame_data_length
        ).await?;

        info!("ğŸ¯ æ–‡ä»¶å¤„ç†å®Œæˆ: {} ä¸ªå¸§åºåˆ—", frame_results.len());

        Ok(ProcessingResult {
            file_path: file_path.clone(),
            total_frames: frame_results.iter().map(|r| r.frame_count).sum(),
            frame_sequences: frame_results,
            original_size: file_mapping.len(),
            compressed_size: compressed_data_length,
            decompressed_size: decompressed_data.len(),
        })
    }

    /// è§£å‹æ•°æ®
    async fn decompress_data(&self, compressed_data: &[u8]) -> Result<canp::zero_copy_memory_pool::ZeroCopyBuffer> {
        // é¢„ä¼°è§£å‹åå¤§å°ï¼ˆé€šå¸¸æ¯”å‹ç¼©æ•°æ®å¤§3-10å€ï¼‰
        let estimated_size = compressed_data.len() * 5;
        
        // ä»æ± ä¸­è·å–ç¼“å†²åŒº
        let mut buffer = self.pool.get_decompress_buffer(estimated_size).await;

        // ä½¿ç”¨gzipè§£å‹
        let mut decoder = GzDecoder::new(compressed_data);
        let mut temp_vec = Vec::new();
        decoder.read_to_end(&mut temp_vec)
            .map_err(|e| anyhow::anyhow!("è§£å‹å¤±è´¥: {}", e))?;

        // å°†è§£å‹ç»“æœå†™å…¥ç¼“å†²åŒº
        buffer.put_slice(&temp_vec);

        // å†»ç»“ä¸ºé›¶æ‹·è´ç¼“å†²åŒº
        Ok(buffer.freeze())
    }

    /// å¤„ç†å¸§åºåˆ—æ•°æ®ï¼ˆé›¶æ‹·è´ï¼‰
    async fn process_frame_sequences(
        &self,
        decompressed_data: &canp::zero_copy_memory_pool::ZeroCopyBuffer,
        offset: usize,
        total_length: usize,
    ) -> Result<Vec<FrameSequenceResult>> {
        let mut results = Vec::new();
        let mut current_offset = offset;
        let data_slice = decompressed_data.as_slice();

        while current_offset < offset + total_length {
            // ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è¯»å–16å­—èŠ‚é•¿åº¦ä¿¡æ¯
            if current_offset + 16 > data_slice.len() {
                break;
            }

            // è§£æå¸§åºåˆ—é•¿åº¦ï¼ˆ16å­—èŠ‚ä¸­çš„12-15å­—èŠ‚ï¼‰
            let length_bytes = &data_slice[current_offset + 12..current_offset + 16];
            let sequence_length = u32::from_be_bytes([
                length_bytes[0], length_bytes[1], length_bytes[2], length_bytes[3]
            ]) as usize;

            if current_offset + 16 + sequence_length > data_slice.len() {
                warn!("âš ï¸ å¸§åºåˆ—é•¿åº¦è¶…å‡ºæ•°æ®èŒƒå›´ï¼Œè·³è¿‡");
                break;
            }

            // é›¶æ‹·è´æå–å¸§åºåˆ—æ•°æ®
            let sequence_data = &data_slice[current_offset + 16..current_offset + 16 + sequence_length];
            
            // å¤„ç†å•ä¸ªå¸§åºåˆ—ï¼ˆè¿™é‡Œåªæ˜¯è®¡æ•°ï¼Œå®é™…åº”è¯¥ç”¨DBCè§£æï¼‰
            let frame_count = self.count_frames_in_sequence(sequence_data);

            results.push(FrameSequenceResult {
                offset: current_offset,
                length: sequence_length,
                frame_count,
            });

            current_offset += 16 + sequence_length;
        }

        Ok(results)
    }

    /// è®¡ç®—å¸§åºåˆ—ä¸­çš„å¸§æ•°é‡ï¼ˆæ¨¡æ‹ŸCANå¸§è§£æï¼‰
    fn count_frames_in_sequence(&self, sequence_data: &[u8]) -> usize {
        // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå‡è®¾æ¯ä¸ªCANå¸§8å­—èŠ‚
        // å®é™…åº”è¯¥ä½¿ç”¨can-dbcåº“è¿›è¡Œè§£æ
        sequence_data.len() / 8
    }

    /// æ‰¹é‡å¤„ç†æ–‡ä»¶
    pub async fn process_batch(&self, batch_size: usize) -> Result<Vec<ProcessingResult>> {
        let mut results = Vec::new();
        
        for chunk in self.file_paths.chunks(batch_size) {
            info!("ğŸš€ å¼€å§‹å¤„ç†æ‰¹æ¬¡: {} ä¸ªæ–‡ä»¶", chunk.len());
            
            // å¹¶å‘å¤„ç†æ‰¹æ¬¡ä¸­çš„æ–‡ä»¶
            let batch_futures: Vec<_> = chunk
                .iter()
                .map(|path| self.process_single_file(path))
                .collect();

            for future in batch_futures {
                match future.await {
                    Ok(result) => results.push(result),
                    Err(e) => error!("âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {}", e),
                }
            }

            // æ¸…ç†è¿‡æœŸçš„æ–‡ä»¶æ˜ å°„ç¼“å­˜
            self.pool.cleanup_expired_mappings();
            
            info!("âœ… æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œå½“å‰å†…å­˜ä½¿ç”¨: {} MB", 
                  self.pool.get_memory_usage() / 1024 / 1024);
        }

        Ok(results)
    }

    /// å¤„ç†æ‰€æœ‰æ–‡ä»¶
    pub async fn process_all(&self) -> Result<ProcessingSummary> {
        info!("ğŸ¯ å¼€å§‹å¤„ç†æ‰€æœ‰æ–‡ä»¶: {} ä¸ª", self.file_paths.len());
        
        let start_time = std::time::Instant::now();
        let results = self.process_batch(50).await?; // æ¯æ‰¹å¤„ç†50ä¸ªæ–‡ä»¶
        let duration = start_time.elapsed();

        let summary = ProcessingSummary {
            total_files: self.file_paths.len(),
            successful_files: results.len(),
            total_frames: results.iter().map(|r| r.total_frames).sum(),
            total_original_size: results.iter().map(|r| r.original_size).sum(),
            total_compressed_size: results.iter().map(|r| r.compressed_size).sum(),
            total_decompressed_size: results.iter().map(|r| r.decompressed_size).sum(),
            processing_duration: duration,
            throughput_mb_per_sec: {
                let total_mb = results.iter().map(|r| r.original_size).sum::<usize>() as f64 / 1024.0 / 1024.0;
                total_mb / duration.as_secs_f64()
            },
        };

        info!("ğŸ‰ å¤„ç†å®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯: {:#?}", summary);
        Ok(summary)
    }
}

/// å¤„ç†ç»“æœ
#[derive(Debug)]
pub struct ProcessingResult {
    pub file_path: PathBuf,
    pub total_frames: usize,
    pub frame_sequences: Vec<FrameSequenceResult>,
    pub original_size: usize,
    pub compressed_size: usize,
    pub decompressed_size: usize,
}

/// å¸§åºåˆ—ç»“æœ
#[derive(Debug)]
pub struct FrameSequenceResult {
    pub offset: usize,
    pub length: usize,
    pub frame_count: usize,
}

/// å¤„ç†æ€»ç»“
#[derive(Debug)]
pub struct ProcessingSummary {
    pub total_files: usize,
    pub successful_files: usize,
    pub total_frames: usize,
    pub total_original_size: usize,
    pub total_compressed_size: usize,
    pub total_decompressed_size: usize,
    pub processing_duration: std::time::Duration,
    pub throughput_mb_per_sec: f64,
}

#[tokio::main]
async fn main() -> Result<()> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt::init();

    // æ¨¡æ‹Ÿ8000ä¸ªæ–‡ä»¶è·¯å¾„ï¼ˆå®é™…ä½¿ç”¨æ—¶ä»ç›®å½•æ‰«æè·å–ï¼‰
    // ä½¿ç”¨ç”Ÿæˆçš„æµ‹è¯•æ•°æ®æ–‡ä»¶
    let test_data_dir = PathBuf::from("test_data");
    let mut file_paths = Vec::new();
    
    if test_data_dir.exists() {
        for entry in std::fs::read_dir(&test_data_dir)? {
            let entry = entry?;
            let path = entry.path();
            if path.is_file() && path.extension().map_or(false, |ext| ext == "bin") {
                file_paths.push(path);
            }
        }
    }
    
    if file_paths.is_empty() {
        eprintln!("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶ï¼");
        eprintln!("ğŸ’¡ è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆæµ‹è¯•æ•°æ®:");
        eprintln!("   cargo run --example generate_test_data");
        return Ok(());
    }
    
    file_paths.sort(); // ç¡®ä¿å¤„ç†é¡ºåºä¸€è‡´
    println!("ğŸ“ æ‰¾åˆ° {} ä¸ªæµ‹è¯•æ–‡ä»¶", file_paths.len());

    // åˆ›å»ºå¤„ç†ä»»åŠ¡
    let task = DataProcessingTask::new(file_paths);

    // å¤„ç†æ‰€æœ‰æ–‡ä»¶
    match task.process_all().await {
        Ok(summary) => {
            println!("ğŸ¯ å¤„ç†æ€»ç»“:");
            println!("  ğŸ“ æ€»æ–‡ä»¶æ•°: {}", summary.total_files);
            println!("  âœ… æˆåŠŸå¤„ç†: {}", summary.successful_files);
            println!("  ğŸ² æ€»å¸§æ•°: {}", summary.total_frames);
            println!("  ğŸ“Š åŸå§‹æ•°æ®: {} MB", summary.total_original_size / 1024 / 1024);
            println!("  ğŸ“¦ å‹ç¼©æ•°æ®: {} MB", summary.total_compressed_size / 1024 / 1024);
            println!("  ğŸ”“ è§£å‹æ•°æ®: {} MB", summary.total_decompressed_size / 1024 / 1024);
            println!("  â±ï¸ å¤„ç†æ—¶é—´: {:.2}s", summary.processing_duration.as_secs_f64());
            println!("  ğŸš€ ååé‡: {:.2} MB/s", summary.throughput_mb_per_sec);
            
            let compression_ratio = summary.total_compressed_size as f64 / summary.total_decompressed_size as f64;
            println!("  ğŸ“ˆ å‹ç¼©æ¯”: {:.2}", compression_ratio);
        }
        Err(e) => {
            error!("âŒ å¤„ç†å¤±è´¥: {}", e);
        }
    }

    Ok(())
}