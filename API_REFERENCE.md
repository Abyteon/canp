# CANP API å‚è€ƒæ–‡æ¡£

## ğŸ“š æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›äº†CANPåº“çš„å®Œæ•´APIå‚è€ƒï¼ŒåŒ…æ‹¬æ‰€æœ‰å…¬å…±æ¥å£ã€æ•°æ®ç»“æ„ã€é…ç½®é€‰é¡¹å’Œä½¿ç”¨ç¤ºä¾‹ã€‚

## ğŸ—ï¸ æ ¸å¿ƒæ¨¡å—

### é›¶æ‹·è´å†…å­˜æ±  (Zero-Copy Memory Pool)

#### ç»“æ„ä½“

##### `ZeroCopyMemoryPool`

é›¶æ‹·è´å†…å­˜æ± çš„ä¸»è¦ç»“æ„ä½“ï¼Œæä¾›é«˜æ•ˆçš„å†…å­˜ç®¡ç†ã€‚

```rust
pub struct ZeroCopyMemoryPool {
    decompress_pools: Vec<Arc<LockPool<BytesMut, 64, 512>>>,
    mmap_cache: Arc<RwLock<lru::LruCache<String, Arc<Mmap>>>>,
    current_memory_usage: Arc<RwLock<usize>>,
}
```

**æ–¹æ³•**:

###### `new(config: MemoryPoolConfig) -> Self`

åˆ›å»ºæ–°çš„å†…å­˜æ± å®ä¾‹ã€‚

```rust
let config = MemoryPoolConfig::default();
let pool = ZeroCopyMemoryPool::new(config);
```

###### `get_decompress_buffer(&self, size: usize) -> MutableMemoryBuffer`

è·å–è§£å‹ç¼©ç¼“å†²åŒºã€‚

```rust
let buffer = pool.get_decompress_buffer(1024)?;
assert!(buffer.buffer.capacity() >= 1024);
```

###### `get_decompress_buffers_batch(&self, sizes: &[usize]) -> Vec<MutableMemoryBuffer>`

æ‰¹é‡è·å–è§£å‹ç¼©ç¼“å†²åŒºã€‚

```rust
let sizes = vec![1024, 2048, 4096];
let buffers = pool.get_decompress_buffers_batch(&sizes);
assert_eq!(buffers.len(), 3);
```

###### `map_file<P: AsRef<Path>>(&self, file_path: P) -> Result<MemoryMappedBlock>`

å†…å­˜æ˜ å°„æ–‡ä»¶ã€‚

```rust
let mapped_file = pool.map_file("data.bin")?;
let data = mapped_file.as_slice();
```

###### `get_stats(&self) -> MemoryPoolStats`

è·å–å†…å­˜æ± ç»Ÿè®¡ä¿¡æ¯ã€‚

```rust
let stats = pool.get_stats();
println!("å½“å‰å†…å­˜ä½¿ç”¨: {}MB", stats.total_memory_usage_mb);
```

##### `MemoryPoolConfig`

å†…å­˜æ± é…ç½®ç»“æ„ä½“ã€‚

```rust
pub struct MemoryPoolConfig {
    pub decompress_buffer_sizes: Vec<usize>,
    pub mmap_cache_size: usize,
    pub max_memory_usage: usize,
    pub memory_warning_threshold: f64,
}
```

**é»˜è®¤å€¼**:
- `decompress_buffer_sizes`: `[1024, 2048, 4096, 8192, 16384]`
- `mmap_cache_size`: `1000`
- `max_memory_usage`: `1024 * 1024 * 1024` (1GB)
- `memory_warning_threshold`: `0.8`

##### `MemoryPoolStats`

å†…å­˜æ± ç»Ÿè®¡ä¿¡æ¯ã€‚

```rust
pub struct MemoryPoolStats {
    pub total_memory_usage_mb: f64,
    pub mmap_cache_hits: usize,
    pub mmap_cache_misses: usize,
    pub decompress_buffer_allocations: usize,
    pub decompress_buffer_releases: usize,
}
```

##### `MemoryMappedBlock`

å†…å­˜æ˜ å°„å—ã€‚

```rust
pub struct MemoryMappedBlock {
    mmap: Arc<Mmap>,
    file_path: PathBuf,
}
```

**æ–¹æ³•**:

###### `as_slice(&self) -> &[u8]`

è·å–æ•°æ®åˆ‡ç‰‡ã€‚

```rust
let data = mapped_block.as_slice();
```

###### `len(&self) -> usize`

è·å–æ•°æ®é•¿åº¦ã€‚

```rust
let length = mapped_block.len();
```

##### `MutableMemoryBuffer`

å¯å˜å†…å­˜ç¼“å†²åŒºã€‚

```rust
pub struct MutableMemoryBuffer {
    buffer: BytesMut,
}
```

**æ–¹æ³•**:

###### `len(&self) -> usize`

è·å–ç¼“å†²åŒºé•¿åº¦ã€‚

```rust
let length = buffer.len();
```

###### `capacity(&self) -> usize`

è·å–ç¼“å†²åŒºå®¹é‡ã€‚

```rust
let capacity = buffer.capacity();
```

###### `extend_from_slice(&mut self, data: &[u8])`

æ‰©å±•ç¼“å†²åŒºã€‚

```rust
buffer.extend_from_slice(b"hello world");
```

### é«˜æ€§èƒ½æ‰§è¡Œå™¨ (High-Performance Executor)

#### ç»“æ„ä½“

##### `HighPerformanceExecutor`

é«˜æ€§èƒ½æ‰§è¡Œå™¨ï¼Œæ”¯æŒæ··åˆä»»åŠ¡ç±»å‹ã€‚

```rust
pub struct HighPerformanceExecutor {
    io_task_tx: mpsc::UnboundedSender<(TaskMetadata, BoxedTask)>,
    cpu_task_tx: mpsc::UnboundedSender<(TaskMetadata, BoxedCpuTask)>,
    priority_task_tx: mpsc::UnboundedSender<(TaskMetadata, BoxedTask)>,
    backpressure_semaphore: Arc<Semaphore>,
}
```

**æ–¹æ³•**:

###### `new(config: ExecutorConfig) -> Self`

åˆ›å»ºæ–°çš„æ‰§è¡Œå™¨å®ä¾‹ã€‚

```rust
let config = ExecutorConfig::default();
let executor = HighPerformanceExecutor::new(config);
```

###### `submit_io_task<F>(&self, priority: Priority, task: F) -> Result<()>`

æäº¤IOå¯†é›†å‹ä»»åŠ¡ã€‚

```rust
executor.submit_io_task(Priority::Normal, || async {
    // æ–‡ä»¶è¯»å–ä»»åŠ¡
    Ok(())
})?;
```

###### `submit_cpu_task<F>(&self, priority: Priority, task: F) -> Result<()>`

æäº¤CPUå¯†é›†å‹ä»»åŠ¡ã€‚

```rust
executor.submit_cpu_task(Priority::High, || {
    // æ•°æ®è§£æä»»åŠ¡
    Ok(())
})?;
```

###### `submit_priority_task<F>(&self, task: F) -> Result<()>`

æäº¤é«˜ä¼˜å…ˆçº§ä»»åŠ¡ã€‚

```rust
executor.submit_priority_task(|| async {
    // é”™è¯¯å¤„ç†ä»»åŠ¡
    Ok(())
})?;
```

###### `get_stats(&self) -> ExecutorStats`

è·å–æ‰§è¡Œå™¨ç»Ÿè®¡ä¿¡æ¯ã€‚

```rust
let stats = executor.get_stats();
println!("å®Œæˆä»»åŠ¡: {}", stats.completed_tasks);
```

###### `shutdown(&self) -> Result<()>`

å…³é—­æ‰§è¡Œå™¨ã€‚

```rust
executor.shutdown()?;
```

##### `ExecutorConfig`

æ‰§è¡Œå™¨é…ç½®ç»“æ„ä½“ã€‚

```rust
pub struct ExecutorConfig {
    pub io_worker_threads: usize,
    pub cpu_worker_threads: usize,
    pub max_queue_length: usize,
    pub task_timeout: Duration,
    pub enable_work_stealing: bool,
}
```

**é»˜è®¤å€¼**:
- `io_worker_threads`: `num_cpus::get() / 2`
- `cpu_worker_threads`: `num_cpus::get()`
- `max_queue_length`: `10000`
- `task_timeout`: `Duration::from_secs(300)`
- `enable_work_stealing`: `true`

##### `ExecutorStats`

æ‰§è¡Œå™¨ç»Ÿè®¡ä¿¡æ¯ã€‚

```rust
pub struct ExecutorStats {
    pub total_tasks: usize,
    pub completed_tasks: usize,
    pub failed_tasks: usize,
    pub io_tasks: usize,
    pub cpu_tasks: usize,
    pub priority_tasks: usize,
    pub avg_execution_time_ms: f64,
}
```

##### `TaskType`

ä»»åŠ¡ç±»å‹æšä¸¾ã€‚

```rust
pub enum TaskType {
    IoIntensive,
    CpuIntensive,
    Mixed,
    HighPriority,
    Custom(u32),
}
```

**æ–¹æ³•**:

###### `suggested_pool(&self) -> &'static str`

è·å–å»ºè®®çš„æ‰§è¡Œæ± ã€‚

```rust
let pool = TaskType::IoIntensive.suggested_pool(); // "io"
```

###### `weight(&self) -> u32`

è·å–ä»»åŠ¡æƒé‡ã€‚

```rust
let weight = TaskType::HighPriority.weight(); // 10
```

###### `suggested_batch_size(&self) -> usize`

è·å–å»ºè®®çš„æ‰¹å¤„ç†å¤§å°ã€‚

```rust
let batch_size = TaskType::CpuIntensive.suggested_batch_size(); // 15
```

##### `Priority`

ä»»åŠ¡ä¼˜å…ˆçº§æšä¸¾ã€‚

```rust
pub enum Priority {
    Low = 0,
    Normal = 1,
    High = 2,
    Critical = 3,
}
```

##### `TaskMetadata`

ä»»åŠ¡å…ƒæ•°æ®ã€‚

```rust
pub struct TaskMetadata {
    pub id: u64,
    pub task_type: TaskType,
    pub priority: Priority,
    pub created_at: Instant,
}
```

### DBCè§£æå™¨ (DBC Parser)

#### ç»“æ„ä½“

##### `DbcManager`

DBCæ–‡ä»¶ç®¡ç†å™¨ã€‚

```rust
pub struct DbcManager {
    dbc_cache: Arc<RwLock<HashMap<PathBuf, DbcCacheEntry>>>,
    stats: Arc<RwLock<DbcParsingStats>>,
}
```

**æ–¹æ³•**:

###### `new(config: DbcManagerConfig) -> Self`

åˆ›å»ºæ–°çš„DBCç®¡ç†å™¨ã€‚

```rust
let config = DbcManagerConfig::default();
let manager = DbcManager::new(config);
```

###### `load_dbc_file<P: AsRef<Path>>(&self, file_path: P, priority: Option<i32>) -> Result<()>`

åŠ è½½DBCæ–‡ä»¶ã€‚

```rust
manager.load_dbc_file("vehicle.dbc", Some(0))?;
```

###### `load_dbc_directory<P: AsRef<Path>>(&self, dir_path: P) -> Result<usize>`

åŠ è½½DBCç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ã€‚

```rust
let count = manager.load_dbc_directory("dbc_files")?;
println!("åŠ è½½äº† {} ä¸ªDBCæ–‡ä»¶", count);
```

###### `parse_can_frame(&self, frame: &CanFrame) -> Result<Option<ParsedMessage>>`

è§£æCANå¸§ã€‚

```rust
let parsed = manager.parse_can_frame(&can_frame)?;
if let Some(message) = parsed {
    println!("è§£æåˆ°æ¶ˆæ¯: {}", message.name);
}
```

###### `get_stats(&self) -> DbcParsingStats`

è·å–è§£æç»Ÿè®¡ä¿¡æ¯ã€‚

```rust
let stats = manager.get_stats();
println!("è§£æå¸§æ•°: {}", stats.parsed_frames);
```

###### `reset_stats(&self)`

é‡ç½®ç»Ÿè®¡ä¿¡æ¯ã€‚

```rust
manager.reset_stats();
```

##### `DbcManagerConfig`

DBCç®¡ç†å™¨é…ç½®ã€‚

```rust
pub struct DbcManagerConfig {
    pub max_cached_files: usize,
    pub cache_expire_seconds: u64,
    pub auto_reload: bool,
    pub parallel_loading: bool,
    pub max_load_threads: usize,
}
```

**é»˜è®¤å€¼**:
- `max_cached_files`: `100`
- `cache_expire_seconds`: `3600`
- `auto_reload`: `true`
- `parallel_loading`: `true`
- `max_load_threads`: `4`

##### `DbcParsingStats`

DBCè§£æç»Ÿè®¡ä¿¡æ¯ã€‚

```rust
pub struct DbcParsingStats {
    pub parsed_frames: usize,
    pub unknown_messages: usize,
    pub cache_hits: usize,
    pub cache_misses: usize,
    pub total_parse_time_ms: u64,
}
```

##### `CanFrame`

CANå¸§ç»“æ„ä½“ã€‚

```rust
pub struct CanFrame {
    pub id: u32,
    pub dlc: u8,
    pub data: Vec<u8>,
    pub timestamp: u64,
    pub frame_type: CanFrameType,
    pub is_remote: bool,
}
```

##### `CanFrameType`

CANå¸§ç±»å‹æšä¸¾ã€‚

```rust
pub enum CanFrameType {
    Standard,  // æ ‡å‡†å¸§ (11ä½ID)
    Extended,  // æ‰©å±•å¸§ (29ä½ID)
}
```

##### `ParsedMessage`

è§£æåçš„æ¶ˆæ¯ã€‚

```rust
pub struct ParsedMessage {
    pub name: String,
    pub id: u32,
    pub signals: Vec<ParsedSignal>,
    pub source_dbc: PathBuf,
}
```

##### `ParsedSignal`

è§£æåçš„ä¿¡å·ã€‚

```rust
pub struct ParsedSignal {
    pub name: String,
    pub raw_value: u64,
    pub physical_value: f64,
    pub unit: Option<String>,
    pub value_description: Option<String>,
}
```

### æ•°æ®å±‚è§£æå™¨ (Data Layer Parser)

#### ç»“æ„ä½“

##### `DataLayerParser`

æ•°æ®å±‚è§£æå™¨ã€‚

```rust
pub struct DataLayerParser {
    memory_pool: ZeroCopyMemoryPool,
    stats: ParsingStats,
}
```

**æ–¹æ³•**:

###### `new(memory_pool: ZeroCopyMemoryPool) -> Self`

åˆ›å»ºæ–°çš„æ•°æ®å±‚è§£æå™¨ã€‚

```rust
let memory_pool = ZeroCopyMemoryPool::default();
let parser = DataLayerParser::new(memory_pool);
```

###### `parse_file(&mut self, file_data: &[u8]) -> Result<ParsedFileData>`

è§£ææ–‡ä»¶æ•°æ®ã€‚

```rust
let parsed_data = parser.parse_file(&file_data).await?;
println!("è§£æäº† {} ä¸ªå¸§åºåˆ—", parsed_data.frame_sequences.len());
```

###### `get_stats(&self) -> ParsingStats`

è·å–è§£æç»Ÿè®¡ä¿¡æ¯ã€‚

```rust
let stats = parser.get_stats();
println!("è§£ææ–‡ä»¶æ•°: {}", stats.files_parsed);
```

##### `ParsingStats`

è§£æç»Ÿè®¡ä¿¡æ¯ã€‚

```rust
pub struct ParsingStats {
    pub files_parsed: usize,
    pub frame_sequences_parsed: usize,
    pub total_frames: usize,
    pub total_bytes_processed: usize,
    pub avg_parse_time_ms: f64,
}
```

##### `ParsedFileData`

è§£æåçš„æ–‡ä»¶æ•°æ®ã€‚

```rust
pub struct ParsedFileData {
    pub file_header: FileHeader,
    pub decompressed_header: DecompressedHeader,
    pub frame_sequences: Vec<FrameSequence>,
}
```

##### `FileHeader`

æ–‡ä»¶å¤´éƒ¨ã€‚

```rust
pub struct FileHeader {
    pub magic: [u8; 4],
    pub version: u8,
    pub flags: u8,
    pub reserved: [u8; 26],
    pub compressed_length: u32,
}
```

**æ–¹æ³•**:

###### `validate(&self) -> Result<()>`

éªŒè¯æ–‡ä»¶å¤´éƒ¨ã€‚

```rust
file_header.validate()?;
```

##### `DecompressedHeader`

è§£å‹å¤´éƒ¨ã€‚

```rust
pub struct DecompressedHeader {
    pub magic: [u8; 4],
    pub version: u8,
    pub flags: u8,
    pub reserved: [u8; 10],
    pub decompressed_length: u32,
}
```

##### `FrameSequence`

å¸§åºåˆ—ã€‚

```rust
pub struct FrameSequence {
    pub length: u32,
    pub reserved: [u8; 12],
    pub frames: Vec<CanFrame>,
}
```

### åˆ—å¼å­˜å‚¨ (Columnar Storage)

#### ç»“æ„ä½“

##### `ColumnarStorageWriter`

åˆ—å¼å­˜å‚¨å†™å…¥å™¨ã€‚

```rust
pub struct ColumnarStorageWriter {
    partition_strategy: PartitionStrategy,
    compression: CompressionType,
    record_batches: Vec<RecordBatch>,
}
```

**æ–¹æ³•**:

###### `new(config: ColumnarStorageConfig) -> Self`

åˆ›å»ºæ–°çš„åˆ—å¼å­˜å‚¨å†™å…¥å™¨ã€‚

```rust
let config = ColumnarStorageConfig::default();
let writer = ColumnarStorageWriter::new(config);
```

###### `write_batch(&mut self, batch: RecordBatch) -> Result<()>`

å†™å…¥è®°å½•æ‰¹æ¬¡ã€‚

```rust
writer.write_batch(record_batch)?;
```

###### `flush(&mut self) -> Result<()>`

åˆ·æ–°æ•°æ®åˆ°ç£ç›˜ã€‚

```rust
writer.flush()?;
```

##### `ColumnarStorageConfig`

åˆ—å¼å­˜å‚¨é…ç½®ã€‚

```rust
pub struct ColumnarStorageConfig {
    pub output_dir: PathBuf,
    pub partition_strategy: PartitionStrategy,
    pub compression: CompressionType,
    pub batch_size: usize,
    pub max_file_size: usize,
}
```

**é»˜è®¤å€¼**:
- `output_dir`: `PathBuf::from("output")`
- `partition_strategy`: `PartitionStrategy::TimeBased { interval: Duration::from_secs(3600) }`
- `compression`: `CompressionType::Snappy`
- `batch_size`: `10000`
- `max_file_size`: `100 * 1024 * 1024` (100MB)

##### `PartitionStrategy`

åˆ†åŒºç­–ç•¥æšä¸¾ã€‚

```rust
pub enum PartitionStrategy {
    TimeBased { interval: Duration },
    IdBased { bucket_count: usize },
    Custom { partition_fn: Box<dyn Fn(&RecordBatch) -> String> },
}
```

##### `CompressionType`

å‹ç¼©ç±»å‹æšä¸¾ã€‚

```rust
pub enum CompressionType {
    Uncompressed,
    Snappy,
    Gzip,
    Lz4,
    Zstd,
}
```

### å¤„ç†æµæ°´çº¿ (Processing Pipeline)

#### ç»“æ„ä½“

##### `DataProcessingPipeline`

æ•°æ®å¤„ç†æµæ°´çº¿ã€‚

```rust
pub struct DataProcessingPipeline {
    config: PipelineConfig,
    memory_pool: Arc<ZeroCopyMemoryPool>,
    executor: Arc<HighPerformanceExecutor>,
    dbc_manager: Arc<DbcManager>,
    storage_writer: Arc<ColumnarStorageWriter>,
}
```

**æ–¹æ³•**:

###### `new(config: PipelineConfig) -> Self`

åˆ›å»ºæ–°çš„å¤„ç†æµæ°´çº¿ã€‚

```rust
let config = PipelineConfig::default();
let pipeline = DataProcessingPipeline::new(config);
```

###### `process_files(&self) -> Result<ProcessingResult>`

å¤„ç†æ–‡ä»¶ã€‚

```rust
let result = pipeline.process_files().await?;
println!("å¤„ç†å®Œæˆ: {:?}", result);
```

##### `PipelineConfig`

æµæ°´çº¿é…ç½®ã€‚

```rust
pub struct PipelineConfig {
    pub input_dir: PathBuf,
    pub output_dir: PathBuf,
    pub batch_size: usize,
    pub max_workers: usize,
    pub max_memory_usage: usize,
    pub enable_compression: bool,
}
```

**é»˜è®¤å€¼**:
- `input_dir`: `PathBuf::from("input")`
- `output_dir`: `PathBuf::from("output")`
- `batch_size`: `100`
- `max_workers`: `num_cpus::get()`
- `max_memory_usage`: `1024 * 1024 * 1024` (1GB)
- `enable_compression`: `true`

##### `ProcessingResult`

å¤„ç†ç»“æœã€‚

```rust
pub struct ProcessingResult {
    pub files_processed: usize,
    pub frames_parsed: usize,
    pub bytes_processed: usize,
    pub processing_time_ms: u64,
    pub output_files: Vec<PathBuf>,
}
```

### æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨ (Test Data Generator)

#### ç»“æ„ä½“

##### `TestDataGenerator`

æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨ã€‚

```rust
pub struct TestDataGenerator {
    config: TestDataConfig,
}
```

**æ–¹æ³•**:

###### `new(config: TestDataConfig) -> Self`

åˆ›å»ºæ–°çš„æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨ã€‚

```rust
let config = TestDataConfig::default();
let generator = TestDataGenerator::new(config);
```

###### `generate_all(&self) -> Result<()>`

ç”Ÿæˆæ‰€æœ‰æµ‹è¯•æ•°æ®ã€‚

```rust
generator.generate_all().await?;
```

###### `generate_single_file(&self, file_index: usize) -> Result<PathBuf>`

ç”Ÿæˆå•ä¸ªæµ‹è¯•æ–‡ä»¶ã€‚

```rust
let file_path = generator.generate_single_file(0)?;
```

##### `TestDataConfig`

æµ‹è¯•æ•°æ®é…ç½®ã€‚

```rust
pub struct TestDataConfig {
    pub output_dir: PathBuf,
    pub file_count: usize,
    pub target_file_size: usize,
    pub frames_per_file: usize,
    pub enable_compression: bool,
}
```

**é»˜è®¤å€¼**:
- `output_dir`: `PathBuf::from("test_data")`
- `file_count`: `10`
- `target_file_size`: `1024 * 1024` (1MB)
- `frames_per_file`: `1000`
- `enable_compression`: `true`

## ğŸ”§ é…ç½®ç¤ºä¾‹

### åŸºæœ¬é…ç½®

```rust
use canp::{
    MemoryPoolConfig,
    ExecutorConfig,
    DbcManagerConfig,
    ColumnarStorageConfig,
    PipelineConfig,
};

// å†…å­˜æ± é…ç½®
let memory_config = MemoryPoolConfig {
    decompress_buffer_sizes: vec![1024, 2048, 4096, 8192],
    mmap_cache_size: 1000,
    max_memory_usage: 1024 * 1024 * 1024, // 1GB
    memory_warning_threshold: 0.8,
};

// æ‰§è¡Œå™¨é…ç½®
let executor_config = ExecutorConfig {
    io_worker_threads: 4,
    cpu_worker_threads: 8,
    max_queue_length: 10000,
    task_timeout: Duration::from_secs(300),
    enable_work_stealing: true,
};

// DBCç®¡ç†å™¨é…ç½®
let dbc_config = DbcManagerConfig {
    max_cached_files: 100,
    cache_expire_seconds: 3600,
    auto_reload: true,
    parallel_loading: true,
    max_load_threads: 4,
};

// åˆ—å¼å­˜å‚¨é…ç½®
let storage_config = ColumnarStorageConfig {
    output_dir: PathBuf::from("output"),
    partition_strategy: PartitionStrategy::TimeBased {
        interval: Duration::from_secs(3600),
    },
    compression: CompressionType::Snappy,
    batch_size: 10000,
    max_file_size: 100 * 1024 * 1024, // 100MB
};

// æµæ°´çº¿é…ç½®
let pipeline_config = PipelineConfig {
    input_dir: PathBuf::from("input"),
    output_dir: PathBuf::from("output"),
    batch_size: 100,
    max_workers: 8,
    max_memory_usage: 1024 * 1024 * 1024, // 1GB
    enable_compression: true,
};
```

### é«˜æ€§èƒ½é…ç½®

```rust
// é«˜æ€§èƒ½å†…å­˜æ± é…ç½®
let high_perf_memory_config = MemoryPoolConfig {
    decompress_buffer_sizes: vec![1024, 2048, 4096, 8192, 16384, 32768],
    mmap_cache_size: 2000,
    max_memory_usage: 2 * 1024 * 1024 * 1024, // 2GB
    memory_warning_threshold: 0.85,
};

// é«˜æ€§èƒ½æ‰§è¡Œå™¨é…ç½®
let high_perf_executor_config = ExecutorConfig {
    io_worker_threads: num_cpus::get() / 2,
    cpu_worker_threads: num_cpus::get(),
    max_queue_length: 50000,
    task_timeout: Duration::from_secs(600),
    enable_work_stealing: true,
};

// é«˜æ€§èƒ½æµæ°´çº¿é…ç½®
let high_perf_pipeline_config = PipelineConfig {
    input_dir: PathBuf::from("input"),
    output_dir: PathBuf::from("output"),
    batch_size: 500,
    max_workers: num_cpus::get(),
    max_memory_usage: 2 * 1024 * 1024 * 1024, // 2GB
    enable_compression: true,
};
```

### å†…å­˜å—é™é…ç½®

```rust
// å†…å­˜å—é™é…ç½®
let memory_constrained_config = MemoryPoolConfig {
    decompress_buffer_sizes: vec![512, 1024, 2048],
    mmap_cache_size: 100,
    max_memory_usage: 512 * 1024 * 1024, // 512MB
    memory_warning_threshold: 0.7,
};

// å†…å­˜å—é™æ‰§è¡Œå™¨é…ç½®
let memory_constrained_executor_config = ExecutorConfig {
    io_worker_threads: 2,
    cpu_worker_threads: 4,
    max_queue_length: 1000,
    task_timeout: Duration::from_secs(300),
    enable_work_stealing: false,
};

// å†…å­˜å—é™æµæ°´çº¿é…ç½®
let memory_constrained_pipeline_config = PipelineConfig {
    input_dir: PathBuf::from("input"),
    output_dir: PathBuf::from("output"),
    batch_size: 50,
    max_workers: 4,
    max_memory_usage: 512 * 1024 * 1024, // 512MB
    enable_compression: true,
};
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```rust
use canp::{
    DataProcessingPipeline,
    PipelineConfig,
    MemoryPoolConfig,
    ExecutorConfig,
    DbcManagerConfig,
    ColumnarStorageConfig,
};
use std::path::PathBuf;
use std::time::Duration;

#[tokio::main]
async fn main() -> Result<()> {
    // 1. é…ç½®å„ä¸ªç»„ä»¶
    let memory_config = MemoryPoolConfig::default();
    let executor_config = ExecutorConfig::default();
    let dbc_config = DbcManagerConfig::default();
    let storage_config = ColumnarStorageConfig::default();
    
    // 2. é…ç½®æµæ°´çº¿
    let pipeline_config = PipelineConfig {
        input_dir: PathBuf::from("data/input"),
        output_dir: PathBuf::from("data/output"),
        batch_size: 100,
        max_workers: 8,
        ..Default::default()
    };
    
    // 3. åˆ›å»ºå¤„ç†æµæ°´çº¿
    let pipeline = DataProcessingPipeline::new(pipeline_config);
    
    // 4. å¤„ç†æ–‡ä»¶
    let result = pipeline.process_files().await?;
    
    println!("å¤„ç†å®Œæˆ:");
    println!("  æ–‡ä»¶æ•°: {}", result.files_processed);
    println!("  å¸§æ•°: {}", result.frames_parsed);
    println!("  å­—èŠ‚æ•°: {}", result.bytes_processed);
    println!("  å¤„ç†æ—¶é—´: {}ms", result.processing_time_ms);
    
    Ok(())
}
```

### é«˜çº§ä½¿ç”¨

```rust
use canp::{
    ZeroCopyMemoryPool,
    HighPerformanceExecutor,
    DbcManager,
    DataLayerParser,
    ColumnarStorageWriter,
    CanFrame,
    TaskType,
    Priority,
};
use std::sync::Arc;

#[tokio::main]
async fn main() -> Result<()> {
    // 1. åˆ›å»ºæ ¸å¿ƒç»„ä»¶
    let memory_pool = Arc::new(ZeroCopyMemoryPool::default());
    let executor = Arc::new(HighPerformanceExecutor::default());
    let dbc_manager = Arc::new(DbcManager::default());
    let storage_writer = Arc::new(ColumnarStorageWriter::default());
    
    // 2. åŠ è½½DBCæ–‡ä»¶
    dbc_manager.load_dbc_file("vehicle.dbc", Some(0)).await?;
    
    // 3. åˆ›å»ºæ•°æ®è§£æå™¨
    let mut parser = DataLayerParser::new(Arc::clone(&memory_pool));
    
    // 4. å¤„ç†æ–‡ä»¶
    let file_data = std::fs::read("data.bin")?;
    let parsed_data = parser.parse_file(&file_data).await?;
    
    // 5. è§£æCANå¸§
    for frame_sequence in &parsed_data.frame_sequences {
        for frame in &frame_sequence.frames {
            if let Some(parsed_message) = dbc_manager.parse_can_frame(frame)? {
                // å¤„ç†è§£æåçš„æ¶ˆæ¯
                println!("è§£æåˆ°æ¶ˆæ¯: {}", parsed_message.name);
                
                // æäº¤å­˜å‚¨ä»»åŠ¡
                let storage_writer = Arc::clone(&storage_writer);
                let message = parsed_message.clone();
                
                executor.submit_cpu_task(Priority::Normal, move || {
                    // å­˜å‚¨æ¶ˆæ¯åˆ°åˆ—å¼å­˜å‚¨
                    Ok(())
                })?;
            }
        }
    }
    
    // 6. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    executor.shutdown()?;
    
    Ok(())
}
```

### æµ‹è¯•æ•°æ®ç”Ÿæˆ

```rust
use canp::{TestDataGenerator, TestDataConfig};
use std::path::PathBuf;

#[tokio::main]
async fn main() -> Result<()> {
    // 1. é…ç½®æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
    let config = TestDataConfig {
        output_dir: PathBuf::from("test_data"),
        file_count: 10,
        target_file_size: 1024 * 1024, // 1MB
        frames_per_file: 1000,
        enable_compression: true,
    };
    
    // 2. åˆ›å»ºç”Ÿæˆå™¨
    let generator = TestDataGenerator::new(config);
    
    // 3. ç”Ÿæˆæµ‹è¯•æ•°æ®
    generator.generate_all().await?;
    
    println!("æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆ");
    
    Ok(())
}
```

## ğŸ” é”™è¯¯å¤„ç†

### é”™è¯¯ç±»å‹

CANPä½¿ç”¨`anyhow::Result<T>`ä½œä¸ºç»Ÿä¸€çš„é”™è¯¯ç±»å‹ï¼Œæ‰€æœ‰å…¬å…±APIéƒ½è¿”å›è¿™ä¸ªç±»å‹ã€‚

### å¸¸è§é”™è¯¯å¤„ç†

```rust
use anyhow::{Result, Context};

// å¤„ç†æ–‡ä»¶è¯»å–é”™è¯¯
let file_data = std::fs::read("data.bin")
    .context("æ— æ³•è¯»å–æ•°æ®æ–‡ä»¶")?;

// å¤„ç†è§£æé”™è¯¯
let parsed_data = parser.parse_file(&file_data)
    .await
    .context("è§£ææ–‡ä»¶å¤±è´¥")?;

// å¤„ç†DBCè§£æé”™è¯¯
let parsed_message = dbc_manager.parse_can_frame(&frame)
    .context("è§£æCANå¸§å¤±è´¥")?;

// å¤„ç†å­˜å‚¨é”™è¯¯
storage_writer.write_batch(record_batch)
    .context("å†™å…¥æ•°æ®å¤±è´¥")?;
```

### è‡ªå®šä¹‰é”™è¯¯å¤„ç†

```rust
use anyhow::{anyhow, Result};

fn validate_config(config: &PipelineConfig) -> Result<()> {
    if config.batch_size == 0 {
        return Err(anyhow!("æ‰¹å¤„ç†å¤§å°ä¸èƒ½ä¸º0"));
    }
    
    if config.max_workers == 0 {
        return Err(anyhow!("å·¥ä½œçº¿ç¨‹æ•°ä¸èƒ½ä¸º0"));
    }
    
    if !config.input_dir.exists() {
        return Err(anyhow!("è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {:?}", config.input_dir));
    }
    
    Ok(())
}
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### ç»Ÿè®¡ä¿¡æ¯æ”¶é›†

```rust
// è·å–å†…å­˜æ± ç»Ÿè®¡
let memory_stats = memory_pool.get_stats();
println!("å†…å­˜ä½¿ç”¨: {:.2}MB", memory_stats.total_memory_usage_mb);
println!("ç¼“å­˜å‘½ä¸­ç‡: {:.2}%", 
    memory_stats.mmap_cache_hits as f64 / 
    (memory_stats.mmap_cache_hits + memory_stats.mmap_cache_misses) as f64 * 100.0);

// è·å–æ‰§è¡Œå™¨ç»Ÿè®¡
let executor_stats = executor.get_stats();
println!("å®Œæˆä»»åŠ¡: {}/{}", executor_stats.completed_tasks, executor_stats.total_tasks);
println!("å¹³å‡æ‰§è¡Œæ—¶é—´: {:.2}ms", executor_stats.avg_execution_time_ms);

// è·å–DBCè§£æç»Ÿè®¡
let dbc_stats = dbc_manager.get_stats();
println!("è§£æå¸§æ•°: {}", dbc_stats.parsed_frames);
println!("æœªçŸ¥æ¶ˆæ¯: {}", dbc_stats.unknown_messages);

// è·å–è§£æç»Ÿè®¡
let parsing_stats = parser.get_stats();
println!("è§£ææ–‡ä»¶æ•°: {}", parsing_stats.files_parsed);
println!("è§£æå¸§åºåˆ—æ•°: {}", parsing_stats.frame_sequences_parsed);
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```rust
use std::time::Instant;

// æ€§èƒ½åŸºå‡†æµ‹è¯•
let start = Instant::now();

// æ‰§è¡Œå¤„ç†ä»»åŠ¡
let result = pipeline.process_files().await?;

let duration = start.elapsed();
println!("å¤„ç†æ—¶é—´: {:?}", duration);
println!("ååé‡: {:.2} MB/s", 
    result.bytes_processed as f64 / duration.as_secs_f64() / 1024.0 / 1024.0);
```

---

è¿™ä¸ªAPIå‚è€ƒæ–‡æ¡£æä¾›äº†CANPåº“çš„å®Œæ•´æ¥å£è¯´æ˜ã€‚é€šè¿‡éµå¾ªè¿™äº›APIè®¾è®¡ï¼Œå¼€å‘è€…å¯ä»¥æ„å»ºé«˜æ€§èƒ½çš„CANæ€»çº¿æ•°æ®å¤„ç†åº”ç”¨ã€‚ 